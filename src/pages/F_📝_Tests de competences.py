import streamlit as st
import requests
import numpy as np
import datetime
import uuid

API_URL='http://fastapi:8502'


def st_create_evaluation(etablissement_connaissances_connues, selected_childs_uuid):
    with st.expander("CrÃ©ation de l'Ã©valuation :", expanded=False):
        with st.form(key="tests_creator"):
            titre     = st.text_area ("Titre de l'Ã©valuation :")
            categorie = st.radio     ("SÃ©lectionner la catÃ©gorie de l'Ã©valuation :", ["CS", "DM", "CR"])
            beginning = st.date_input("Date de distribution de l'Ã©valuation aux Ã©lÃ¨ves :")
            collecte  = st.date_input("Date de rendu des Ã©lÃ¨ves :")
            rendu     = st.date_input("Date de rendu de l'enseignant :")
            knowledges = st.multiselect("Quels sont les connaissances utilisÃ©es ?", etablissement_connaissances_connues, [])
            knowledge_NotModel = []#st.session_state["etablissement_connaissances_non_connues"       ]


            if st.form_submit_button (label="Save test", help="Click to save") :
                new_evaluation = {
                    "titre"     : titre,
                    "uuid"      : str(uuid.uuid4()),
                    "category" : categorie, # Ã©valuation surveillÃ©, evaluation Ã  la maison, evaluation rapide
                    "beginning" : beginning.__str__(),
                    "collecte"  : collecte .__str__(),
                    "rendu"     : rendu    .__str__(),
                    "knowledge_model"   : knowledges,
                        # RQ : Ceci devrait Ãªtre une liste de int pour structurer au format
                        # De premiers test avec List[compÃ©tences] sotn faits, puis cela sera Ã  numÃ©riser
                        # avant l'envoi Ã  l'api
                    "knowledge_NotModel": knowledge_NotModel,

                    "childs_evaluated"  : selected_childs_uuid
                        # NB : n'est-ce pas aux Ã©lÃ¨ves que l'on doit assigner k'uuid du test ?
                    #"childs_non_evaluated" : ["uuid5"],
                    #"classe_evaluatede"  : ["class_uuid"]
                    }

                # INSERTION DE CETTE NOUVELLE EVALUATION DANS LA DB
                url = API_URL+f'/add_evaluation/'
                response = requests.post(url, json=new_evaluation, headers=headers)


                # VÃ©rifier la rÃ©ponse
                if response.status_code == 200:
                    st.success('The assessment is created !', icon="âœ…")
                    #st.session_state['evaluations'] += [new_evaluation]
                else:
                    st.error("ðŸ˜• Request failed !")

def st_correction_evaluation_description(user_uuid):
    url = API_URL+f'/user/{user_uuid}/evals'


    headers = {
            "accept" : "application/json",
            "Authorization": f'Bearer {st.session_state["access_token"]}'}
    accessible_evals_encode = requests.get(url, headers=headers)
    accessible_evals = accessible_evals_encode.json()
    if accessible_evals_encode.status_code != 200 : st.warning("ðŸ˜• Error to find evals from API")

    evaluations = accessible_evals
        # NB : la restriction aux Ã©lÃ¨ves sÃ©lectionÃ©s est omise contrairement au cadre
        #      "parent" ou "child".
        # RQ : des conditions prÃ©liminaires de tri sont Ã  faire naÃ®tre ici
        #      (classe, niveau, selected_childs) et respectÃ© par tous les Ã©lÃ¨ves Ã  selectionner
        # NB : il peut Ãªtre acceptÃ© que la fonctionnaligÃ© get soit mise en place juste aprÃ¨s la connexion
        #      Ã  la place de faire l'appel ici
    evaluations_title = list(map(lambda x:x["titre"], evaluations))
    try    : st.session_state['evaluations_select_index'] = evaluations_title.index(evaluation_select["title"])
    except : st.session_state['evaluations_select_index'] = 0

    # if evaluation_title == [] or

    evaluations_select_title = st.radio(
        "Sur quelle Ã©valuation dÃ©sirez-vous entrer les compÃ©tences d'Ã©lÃ¨ves ?",
        evaluations_title, index=st.session_state['evaluations_select_index'] , key="evaluations_select_title")
        # RQ : complÃ©ter cette portion de telle sorte Ã  ce lorsqu'une evaluations_select_title est sÃ©lectionnÃ©e,
        #      le rechargement de la page montre le choix et changement effectuÃ© (?cf var index)
    evaluations_select = [i for i in evaluations if i["titre"]==evaluations_select_title]
    evaluation_select = evaluations_select[0]
    if len(evaluations_select) > 1 : st.info("ðŸ˜• 2 Ã©valuations avec un mÃªme titre !", icon="ðŸš¨")

    return evaluation_select

0*"""
    #######################################
    ######  VARIABLES DESCRIPTION  ########
    #######################################

    user : dictionary with user's description = st.session_state["identification"]

    accessible_evals : dict of evaluations in relation with the user = API(/user/{user_uuid}/evals)
    evaluations : accessibles_evals in relation with selected_clilds
    evaluation_select : evaluation select from evaluations = (radio button)

    selected_childs : childs selected
    childs_evaluated : childs in the evaluation
    childs_evaluated : childs selected in the evaluation = selected_childs INTER childs_evaluated


"""

#if "evaluations" not in st.session_state : st.error("ðŸ˜• BDD connexion error !") # NB "etablissement connaissances connues" est aussi utilisÃ©
if False : pass
elif "identification" not in st.session_state : st.error("ðŸ˜• No valid identification !")
elif  "selected_childs" not in st.session_state: st.error("ðŸ˜• We don't have 'selected_childs'")
#elif len(st.session_state["selected_childs"]) < 2    : st.error("ðŸ˜• No utility to select 'selected_childs'")
elif "child" in st.session_state["identification"]["actual_role"] :
    st.write("C.")
    st.title("Tests de compÃ©tences into the child")

    st.write(st.session_state["identification"])

        # RQ : Cela demande au prÃ©alable que les rÃ©sultats de chaque Ã©valuations
        # auxquelles l'Ã©lÃ¨ve a participÃ© soient rÃ©pertoriÃ©es sur ses donnÃ©es
        # child_evaluations = [evaluations]
        # evaluation = {"evaluation_id":
        #               "results": ... }
        # NB : dans le cadre actuel, toutes les Ã©valuations sont importÃ©es puis
        #  triÃ©es suivant l'existence ou non de l'uuid de l'Ã©lÃ¨ve dans les participants

    user_uuid = st.session_state["identification"]["uuid"]
    headers = {
            "accept" : "application/json",
            "Authorization": f'Bearer {st.session_state["access_token"]}'}
    accessible_evals_encode = requests.get(API_URL+f'/user/{user_uuid}/evals', headers=headers)
    accessible_evals = accessible_evals_encode.json()
        # RQ : actuellement, user peut acceder Ã  toutes les evaluations
        #    par la suite "etablissement_evaluations", "accessible_evaluations", "selected_evaluations"


    child_uuid = st.session_state["selected_childs"][0]["uuid"]
    evaluations = [accessible_eval for accessible_eval in accessible_evals if child_uuid in accessible_eval["childs_evaluated"]]

    evaluation_name = st.radio(
        "Sur quelle Ã©valuation dÃ©sires tu avoir des informations ?",
        list(map(lambda x:x["titre"], evaluations)))

    evaluation_select = [i for i in evaluations if i["titre"]==evaluation_name]
    if len(evaluation_select) > 1 : st.info("ðŸ˜• 2 Ã©valuations avec un mÃªme titre !")
    evaluation_select = evaluation_select[0]

    st.session_state['evaluation_select_id'] = evaluations.index(evaluation_select)

    st.write(evaluation_select)
elif "parent" in st.session_state["identification"]["actual_role"] :
    st.write("P.")
    if len(st.session_state["selected_childs"]) != 1 : st.error("ðŸ˜• You should select one child !")
    else :
        st.write("Tests de compÃ©tences into one of your childs")

        user_uuid = st.session_state["identification"]["uuid"]
        headers = {
            "accept" : "application/json",
            "Authorization": f'Bearer {st.session_state["access_token"]}'}
        accessible_evals_encode = requests.get(API_URL+f'/user/{user_uuid}/evals', headers=headers)
        accessible_evals = accessible_evals_encode.json()
        child_uuid = st.session_state["selected_childs"][0]["uuid"]
        evaluations = [accessible_eval for accessible_eval in accessible_evals if child_uuid in accessible_eval["childs_evaluated"]]

        evaluation_name = st.radio(
            "Sur quelle Ã©valuation dÃ©sires tu avoir des informations ?",
            list(map(lambda x:x["titre"], evaluations)))
        evaluation_select = [i for i in evaluations if i["titre"]==evaluation_name]
        if len(evaluation_select) > 1 : st.info("ðŸ˜• 2 Ã©valuations avec un mÃªme titre !")
        elif not evaluation_select : st.info("ðŸ˜• No assessment selected !")
        evaluation_select = evaluation_select[0]

        st.session_state['evaluation_select_id'] = evaluations.index(evaluation_select)


        st.write(evaluation_select)
elif "teacher" in st.session_state["identification"]["actual_role"] :
    st.title("Tests de compÃ©tences")


    headers = {
            "accept" : "application/json",
            "Authorization": f'Bearer {st.session_state["access_token"]}'}

    etablissement_connaissances_connues     = st.session_state["etablissement_connaissances_connues"    ]
    etablissement_connaissances_non_connues = st.session_state["etablissement_connaissances_non_connues"]
                    # NB : Nous admettons leur existence dans la BDD

    user_uuid = st.session_state["identification"]["uuid"]


    selected_childs = st.session_state["selected_childs"]
        # NB : il est discutable de prendre "selected_childs" ou "etablissement_childs"
        #      cependant, "etablissement_childs" permet Ã  coup sur d'avoir tous les Ã©lÃ¨ves evaluated par le contrÃ´le
    selected_childs_uuid = list(map(lambda x:x["uuid"], selected_childs))
        # RQ : il y a dÃ©bat entre la selection de "accessible_childs" et "selected_childs"

    _ = st_create_evaluation(etablissement_connaissances_connues, selected_childs_uuid)


    evaluation_select = st_correction_evaluation_description(user_uuid)

    evaluation_uuid                     = evaluation_select["uuid"]
    childs_evaluated_uuid               = evaluation_select["childs_evaluated"]
    evaluation_connaissances_attendues  = evaluation_select["knowledge_model"] # ex : = ["PrioritÃ©s opÃ©ratoires","Expressions littÃ©rales"]
    evaluation_connaissances_attendues_index_from_etablissement = list(map(lambda x : etablissement_connaissances_connues.index(x), evaluation_connaissances_attendues))


    childs_evaluated_and_selected           = list(filter(lambda x: x["uuid"] in childs_evaluated_uuid, selected_childs))
    childs_evaluated_and_selected_uuid      = list(map   (lambda x: x["uuid"], childs_evaluated_and_selected))
    childs_evaluated_and_selected_firstName = list(map   (lambda x: x["firstName"][0], childs_evaluated_and_selected))

    with st.expander("Mise Ã  jour de l'Ã©valuation :"):
        with st.form(key="Ã©valuation_modifications"):
            titre     = st.text_area ("Titre de l'Ã©valuation :"                    , evaluation_select["titre"])
            categorie = st.radio     ("SÃ©lectionner la catÃ©gorie de l'Ã©valuation :", ["CS", "DM", "CR"],
                                      index = ["CS", "DM", "CR"].index(evaluation_select["category"]))
            beginning     = st.date_input("Date de distribution de l'Ã©valuation aux Ã©lÃ¨ves :",
                                        datetime.datetime.strptime(evaluation_select["beginning"], '%Y-%m-%d'))
            collecte  = st.date_input("Date de rendu des Ã©lÃ¨ves :",
                                        datetime.datetime.strptime(evaluation_select["collecte"], '%Y-%m-%d'))
            rendu     = st.date_input("Date de rendu de l'enseignant :",
                                        datetime.datetime.strptime(evaluation_select["rendu"], '%Y-%m-%d'))
            knowledges = st.multiselect("Quels sont les connaissances utilisÃ©es ?", st.session_state["etablissement_connaissances_connues"], evaluation_select["knowledge_model"])
            knowledge_NotModel = evaluation_select["knowledge_NotModel"] # RQ : Ã  adapter suivant la mÃªme configuration que la ligne du dessus plus tard

            childs_evaluated = st.multiselect(
                            "Tu dÃ©sires te renseigner sur quel(s) enfants(s) ?",
                            options = evaluation_select["childs_evaluated"], # selected_childs_uuid,
                            default = childs_evaluated_and_selected_uuid) # evaluation_select["childs_evaluated"]
                # NB : default = evaluation_select["childs_evaluated"]
                #      est actuellement refusÃ© car les Ã©lÃ¨ves de l'Ã©valuation ne sont pas nÃ©cessairement
                #      dans l'Ã©valuation => ERROR
            if st.form_submit_button (label="Modification test", help="Click to save") :
                new_evaluation = {
                    "titre"     : titre,
                    "uuid"      : evaluation_select["uuid"],
                    "category"  : categorie, # Ã©valuation surveillÃ©, evaluation Ã  la maison, Ã©valuation rapide
                    "beginning" : beginning.__str__(),
                    "collecte"  : collecte .__str__(),
                    "rendu"     : rendu    .__str__(),
                    "knowledge_model"   : knowledges,
                        # RQ : Ceci devrait Ãªtre une liste de int pour structurer au format
                        # De premiers test avec List[compÃ©tences] sotn faits, puis cela sera Ã  numÃ©riser
                        # avant l'envoi Ã  l'api
                    "knowledge_NotModel": knowledge_NotModel,
                    "childs_evaluated"  : childs_evaluated
                        # NB : n'est-ce pas aux Ã©lÃ¨ves que l'on doit assigner k'uuid du test ?
                    #"childs_non_evaluated" : ["uuid5"],
                    #"classe_evaluatede"  : ["class_uuid"]
                    }

                url = API_URL+f'/delete_evaluation/'
                response = requests.post(url, json=evaluation_select, headers=headers)

                url = API_URL+f'/add_evaluation/'
                response = requests.post(url, json=new_evaluation, headers=headers)


                # VÃ©rifier la rÃ©ponse
                if response.status_code == 200:
                    st.write("RequÃªte de mise Ã  jour rÃ©ussie !")
                    st.experimental_rerun()
                else:
                    st.write("Ã‰chec de la requÃªte :", response.status_code)


    if st.button('Suppression', key=f"suppression_Ã©valuation"):
        url = API_URL+f'/delete_evaluation/'
        response = requests.post(url, json=evaluation_select, headers=headers)

        # VÃ©rifier la rÃ©ponse
        if response.status_code == 200:
            #st.session_state['evaluation_select_id'] = None
            st.experimental_rerun()
            st.write("RequÃªte rÃ©ussie !")
        else:
            st.write("Ã‰chec de la requÃªte :", response.status_code)
            st.write(response.text)  # Afficher le contenu de la rÃ©ponse en texte brut


    if not childs_evaluated_and_selected :
        st.info("ðŸ˜• Aucun des Ã©lÃ¨ves sÃ©lectionÃ©s ne sont prÃ©sents sur ce test !", icon="ðŸš¨")
    else :
        childs_evaluated_and_selected_knowledge = np.concatenate([child["knowledge_Model"] for child in childs_evaluated_and_selected], axis=0).astype(int)
        childs_evaluated_and_selected_knowledge = childs_evaluated_and_selected_knowledge[:,evaluation_connaissances_attendues_index_from_etablissement]

        n_lines = len(evaluation_connaissances_attendues)
        n_cols  = len(childs_evaluated_and_selected)

        with st.expander("Mise Ã  jour des compÃ©tences d'Ã©lÃ¨ves :"):
            if not evaluation_connaissances_attendues :
                st.write("Aucunes compÃ©tences n'a Ã©tÃ© associÃ©e Ã  l'Ã©valuation !")
            else :
                with st.form(key="compÃ©tences_modifications"):
                    # NumÃ©risation des connaissances attendues dans l'Ã©valuation suivant etablissement_connaissances_connues
                    #connaissances_attendues_numerise, _ = numerizer(evaluation_connaissances_attendues, etablissement_connaissances_connues)
                    #st.write( connaissances_attendues_numerise)
                        # RQ : on admet que les connaissances attendues sont connues par le modÃ¨le
                        # Sinon, faire un espace de sÃ©lection d'une notion suivant de teste donnÃ© (env<=> similarity)
                    #connaissances_attendues_numerise_binar = np.max(connaissances_attendues_numerise, axis= 0)
                    #st.write(connaissances_attendues_numerise_binar)
                    #evaluation_connaissances_attendues_index_from_etablissement = [ind for ind, val in enumerate(etablissement_connaissances_connues) if val in evaluation_connaissances_attendues]


                    X = np.zeros((n_lines, n_cols))
                    table_cols_name = [st.columns([1]*(n_cols+1)) for i in range(n_lines+1)]
                    for n_row, table_row in enumerate(table_cols_name):
                        for n_col, table_col in enumerate(table_row):
                            if n_row == 0 and n_col > 0:
                                word = childs_evaluated_and_selected_firstName[n_col-1]
                                table_cols_name[n_row][n_col].write(word)
                            elif n_row > 0 and n_col == 0 :
                                word = evaluation_connaissances_attendues[n_row-1]
                                table_cols_name[n_row][n_col].write(word)
                            elif n_row != 0 and n_col != 0 :
                                value = childs_evaluated_and_selected_knowledge[n_col-1, n_row-1]
                                key = f"selectcompetences_{n_row}_{n_col}"
                                #X[n_row-1][n_col-1] = table_cols_name[n_row][n_col].checkbox("", value = value, key = key)
                                _ = table_cols_name[n_row][n_col].select_slider(
                                                                "hidden",
                                                                label_visibility="hidden",
                                                                options=["NA", "ECA", "A", "T"],
                                                                value=["NA", "ECA", "A", "T"][value],
                                                                key=key)
                                X[n_row-1][n_col-1] = ["NA", "ECA", "A", "T"].index(_)


                    transmission = st.form_submit_button (label="Modification test", help="Click to save")
                    if transmission:
                        # RQ : Cela demande au prÃ©alable que les rÃ©sultats de chaque Ã©valuations
                        # auxquelles l'Ã©lÃ¨ve a participÃ© soient rÃ©pertoriÃ©es sur ses donnÃ©es
                        # child_evaluations = [evaluations]
                        # evaluation = {"evaluation_id":
                        #               "results_model": ...
                        #               "results_notModel": ... }
                        childs_results = np.transpose(X, (1,0))
                        for child, child_results in zip(childs_evaluated_and_selected, childs_results) :
                            evaluation = {"uuid": evaluation_uuid,
                                       "results_model": child_results,
                                       "results_notModel": [] } # RQ : non pris en compte

                            # i
                            child_index = None
                            for i_child, selected_child in enumerate(selected_childs):
                                if selected_child["uuid"]==child["uuid"] :
                                    child_index=i_child
                                    break

                            child_evaluations = st.session_state["selected_childs"][i_child]["results"]
                            in_child_evaluations = False
                            for i_eval, child_evaluation in enumerate(child_evaluations):
                                if child_evaluation["uuid"]==evaluation["uuid"] :
                                    in_child_evaluations = i_eval
                                    break

                            if in_child_evaluations == False :
                                st.session_state["selected_childs"][i_child]["results"] += [evaluation]
                            else : # in_evaluation in |[0, 1, ...]|
                                st.session_state["selected_childs"][i_child]["results"][i_eval] = evaluation

                            # maj de "knowledge_Model" suivant evaluation["results_model"]
                            for i_evaluation_competence, indice_evaluation_connaissance_attendue in enumerate(evaluation_connaissances_attendues_index_from_etablissement) :
                                i_competence = indice_evaluation_connaissance_attendue
                                st.session_state["selected_childs"][i_child]["knowledge_Model"][0][i_competence] = \
                                    evaluation["results_model"][i_evaluation_competence]
                                    #<=>st.session_state["selected_childs"][i_child]["evaluations"][i_eval][i_evaluation_competence]

                        # SAUVEGARDE DES DONNEES DANS LA BDD ETABLISSEMENT
                        evaluation = {
                            "uuid" : evaluation_uuid,
                            "childs_uuid" : childs_evaluated_and_selected_uuid,
                            "childs_competences" : X.tolist(),
                            "etablissement_connaissances_connues" : etablissement_connaissances_connues}

                        url = API_URL+f'/habilities_evaluation/'
                        response = requests.post(url, json=evaluation, headers=headers)
                        if response.status_code == 200:
                            st.success('Skills are saves !', icon="âœ…")
                            #st.experimental_rerun()
                        else:
                            st.error("Ã‰chec de sauvegarde des compÃ©tences Ã©lÃ¨ves sur l'Ã©valuation sÃ©lectionnÃ© dans la DB")





        st.write("<h2>Communication des nouvelles compÃ©tences.</h2>", unsafe_allow_html=True)
        cols = st.tabs(childs_evaluated_and_selected_firstName)
        for i_child_evaluated_and_selected, child_evaluated_and_selected, col in zip(range(len(childs_evaluated_and_selected)), childs_evaluated_and_selected, cols):
            # OK knowledge_model
            habilities = {}
            for evaluation_connaissance_attendue in evaluation_connaissances_attendues :
                index_evaluation_connaissance_attendue = etablissement_connaissances_connues.index(evaluation_connaissance_attendue)
                index_hability = child_evaluated_and_selected["knowledge_Model"][0][index_evaluation_connaissance_attendue]
                hability = ["NA", "ECA", "A", "T"][int(index_hability)]
                habilities[evaluation_connaissance_attendue] = hability
                    # RQ : la liste ["NA", "ECA", "A", "T"] est utilisÃ©e sur de multiples pages
                    #   ->? Mise en place d'une variable gÃ©nÃ©rale ?
                    # RQ : Dans le cadre oÃ¹ hability in ["NA", "ECA"], une prÃ©cision plus prÃ©cise des
                    #      compÃ©tences peut Ãªtre mise en place via :
                    #         -> celles demandÃ©es pour l'acquÃ©rir (notions prÃ©cÃ©dentes)
                    #         -> les actions d'entraÃ®nnement possibles pour l'acquÃ©rir (exercices sur la notion)
            # RQ : ajouter un deuxiÃ¨me for sur evaluation_select["knowledge_NotModel"]

            text_actual_eval = "\n\t\t\t\t".join([""] + [f"- {k} : {v}" for k, v in habilities.items()])

            with col:
                text = f"""Chers parents de {child_evaluated_and_selected["firstName"][0]} :

                Sur l'Ã©valuation effectuÃ©e le {evaluation_select["collecte"]} en mathÃ©matiques, voici le bilan associÃ© Ã  ses compÃ©tences :{text_actual_eval}"""
                # RQ : les sous-catÃ©gories peuvent se formuler ainsi :
                # - ThÃ©orÃ¨me de Pythagore : Non acquis
                #      - Racine carrÃ©e : Non acquis
                #      - Equations du premier degrÃ© : Acquis
                #      - CatÃ©gories de triangles : Acquis
                courriel_content = st.text_area("hidden", label_visibility="hidden", value=text, height=20+35*text.count("\n")+100)
                    # NB : height = ax+b oÃ¹ a et b sont Ã  dÃ©finir

                if st.button('Envoi', key=f"envoi_{i_child_evaluated_and_selected}"):
                    st.write(f'Message envoyÃ© aux parents de {child_evaluated_and_selected["firstName"][0]} :')

