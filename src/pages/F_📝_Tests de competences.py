import streamlit as st
import requests
import numpy as np
import datetime
import uuid

API_URL='http://fastapi:8502'


def st_create_evaluation(etablissement_connaissances_connues, selected_childs_uuid):
    with st.expander("Cr√©ation de l'√©valuation :", expanded=False):
        with st.form(key="tests_creator"):
            titre     = st.text_area ("Titre de l'√©valuation :")
            categorie = st.radio     ("S√©lectionner la cat√©gorie de l'√©valuation :", ["CS", "DM", "CR"])
            beginning = st.date_input("Date de distribution de l'√©valuation aux √©l√®ves :")
            collecte  = st.date_input("Date de rendu des √©l√®ves :")
            rendu     = st.date_input("Date de rendu de l'enseignant :")
            knowledges = st.multiselect("Quels sont les connaissances utilis√©es ?", etablissement_connaissances_connues, [])
            knowledge_NotModel = []#st.session_state["etablissement_connaissances_non_connues"       ]


            if st.form_submit_button (label="Save test", help="Click to save") :
                new_evaluation = {
                    "titre"     : titre,
                    "uuid"      : str(uuid.uuid4()),
                    "category" : categorie, # √©valuation surveill√©, evaluation √† la maison, evaluation rapide
                    "beginning" : beginning.__str__(),
                    "collecte"  : collecte .__str__(),
                    "rendu"     : rendu    .__str__(),
                    "knowledge_model"   : knowledges,
                        # RQ : Ceci devrait √™tre une liste de int pour structurer au format
                        # De premiers test avec List[comp√©tences] sotn faits, puis cela sera √† num√©riser
                        # avant l'envoi √† l'api
                    "knowledge_NotModel": knowledge_NotModel,

                    "childs_evaluated"  : selected_childs_uuid
                        # NB : n'est-ce pas aux √©l√®ves que l'on doit assigner k'uuid du test ?
                    #"childs_non_evaluated" : ["uuid5"],
                    #"classe_evaluatede"  : ["class_uuid"]
                    }

                # INSERTION DE CETTE NOUVELLE EVALUATION DANS LA DB
                url = API_URL+f'/add_evaluation/'
                response = requests.post(url, json=new_evaluation, headers=headers)


                # V√©rifier la r√©ponse
                if response.status_code == 200:
                    st.success('The assessment is created !', icon="‚úÖ")
                    #st.session_state['evaluations'] += [new_evaluation]
                else:
                    st.error("üòï Request failed !")

def st_correction_evaluation_description(user_uuid):
    url = API_URL+f'/user/{user_uuid}/evals'


    headers = {
            "accept" : "application/json",
            "Authorization": f'Bearer {st.session_state["access_token"]}'}
    accessible_evals_encode = requests.get(url, headers=headers)
    accessible_evals = accessible_evals_encode.json()
    if accessible_evals_encode.status_code != 200 : st.warning("üòï Error to find evals from API")

    evaluations = accessible_evals
        # NB : la restriction aux √©l√®ves s√©lection√©s est omise contrairement au cadre
        #      "parent" ou "child".
        # RQ : des conditions pr√©liminaires de tri sont √† faire na√Ætre ici
        #      (classe, niveau, selected_childs) et respect√© par tous les √©l√®ves √† selectionner
        # NB : il peut √™tre accept√© que la fonctionnalig√© get soit mise en place juste apr√®s la connexion
        #      √† la place de faire l'appel ici
    evaluations_title = list(map(lambda x:x["titre"], evaluations))
    try    : st.session_state['evaluations_select_index'] = evaluations_title.index(evaluation_select["title"])
    except : st.session_state['evaluations_select_index'] = 0

    # if evaluation_title == [] or

    evaluations_select_title = st.radio(
        "Sur quelle √©valuation d√©sirez-vous entrer les comp√©tences d'√©l√®ves ?",
        evaluations_title, index=st.session_state['evaluations_select_index'] , key="evaluations_select_title")
        # RQ : compl√©ter cette portion de telle sorte √† ce lorsqu'une evaluations_select_title est s√©lectionn√©e,
        #      le rechargement de la page montre le choix et changement effectu√© (?cf var index)
    evaluations_select = [i for i in evaluations if i["titre"]==evaluations_select_title]
    evaluation_select = evaluations_select[0]
    if len(evaluations_select) > 1 : st.info("üòï 2 √©valuations avec un m√™me titre !", icon="üö®")

    return evaluation_select

0*"""
    #######################################
    ######  VARIABLES DESCRIPTION  ########
    #######################################

    user : dictionary with user's description = st.session_state["identification"]

    accessible_evals : dict of evaluations in relation with the user = API(/user/{user_uuid}/evals)
    evaluations : accessibles_evals in relation with selected_clilds
    evaluation_select : evaluation select from evaluations = (radio button)

    selected_childs : childs selected
    childs_evaluated : childs in the evaluation
    childs_evaluated : childs selected in the evaluation = selected_childs INTER childs_evaluated


"""

#if "evaluations" not in st.session_state : st.error("üòï BDD connexion error !") # NB "etablissement connaissances connues" est aussi utilis√©
if False : pass
elif "identification" not in st.session_state : st.error("üòï No valid identification !")
elif  "selected_childs" not in st.session_state: st.error("üòï We don't have 'selected_childs'")
#elif len(st.session_state["selected_childs"]) < 2    : st.error("üòï No utility to select 'selected_childs'")
elif "child" in st.session_state["identification"]["actual_role"] :
    st.write("C.")
    st.title("Tests de comp√©tences into the child")

    st.write(st.session_state["identification"])

        # RQ : Cela demande au pr√©alable que les r√©sultats de chaque √©valuations
        # auxquelles l'√©l√®ve a particip√© soient r√©pertori√©es sur ses donn√©es
        # child_evaluations = [evaluations]
        # evaluation = {"evaluation_id":
        #               "results": ... }
        # NB : dans le cadre actuel, toutes les √©valuations sont import√©es puis
        #  tri√©es suivant l'existence ou non de l'uuid de l'√©l√®ve dans les participants

    user_uuid = st.session_state["identification"]["uuid"]
    headers = {
            "accept" : "application/json",
            "Authorization": f'Bearer {st.session_state["access_token"]}'}
    accessible_evals_encode = requests.get(API_URL+f'/user/{user_uuid}/evals', headers=headers)
    accessible_evals = accessible_evals_encode.json()
        # RQ : actuellement, user peut acceder √† toutes les evaluations
        #    par la suite "etablissement_evaluations", "accessible_evaluations", "selected_evaluations"


    child_uuid = st.session_state["selected_childs"][0]["uuid"]
    evaluations = [accessible_eval for accessible_eval in accessible_evals if child_uuid in accessible_eval["childs_evaluated"]]

    evaluation_name = st.radio(
        "Sur quelle √©valuation d√©sires tu avoir des informations ?",
        list(map(lambda x:x["titre"], evaluations)))

    evaluation_select = [i for i in evaluations if i["titre"]==evaluation_name]
    if len(evaluation_select) > 1 : st.info("üòï 2 √©valuations avec un m√™me titre !")
    evaluation_select = evaluation_select[0]

    st.session_state['evaluation_select_id'] = evaluations.index(evaluation_select)

    st.write(evaluation_select)
elif "parent" in st.session_state["identification"]["actual_role"] :
    st.write("P.")
    if len(st.session_state["selected_childs"]) != 1 : st.error("üòï You should select one child !")
    else :
        st.write("Tests de comp√©tences into one of your childs")

        user_uuid = st.session_state["identification"]["uuid"]
        headers = {
            "accept" : "application/json",
            "Authorization": f'Bearer {st.session_state["access_token"]}'}
        accessible_evals_encode = requests.get(API_URL+f'/user/{user_uuid}/evals', headers=headers)
        accessible_evals = accessible_evals_encode.json()
        child_uuid = st.session_state["selected_childs"][0]["uuid"]
        evaluations = [accessible_eval for accessible_eval in accessible_evals if child_uuid in accessible_eval["childs_evaluated"]]

        evaluation_name = st.radio(
            "Sur quelle √©valuation d√©sires tu avoir des informations ?",
            list(map(lambda x:x["titre"], evaluations)))
        evaluation_select = [i for i in evaluations if i["titre"]==evaluation_name]
        if len(evaluation_select) > 1 : st.info("üòï 2 √©valuations avec un m√™me titre !")
        elif not evaluation_select : st.info("üòï No assessment selected !")
        evaluation_select = evaluation_select[0]

        st.session_state['evaluation_select_id'] = evaluations.index(evaluation_select)


        st.write(evaluation_select)
elif "teacher" in st.session_state["identification"]["actual_role"] :
    st.title("Tests de comp√©tences")


    headers = {
            "accept" : "application/json",
            "Authorization": f'Bearer {st.session_state["access_token"]}'}

    etablissement_connaissances_connues     = st.session_state["etablissement_connaissances_connues"    ]
    etablissement_connaissances_non_connues = st.session_state["etablissement_connaissances_non_connues"]
                    # NB : Nous admettons leur existence dans la BDD

    user_uuid = st.session_state["identification"]["uuid"]


    selected_childs = st.session_state["selected_childs"]
        # NB : il est discutable de prendre "selected_childs" ou "etablissement_childs"
        #      cependant, "etablissement_childs" permet √† coup sur d'avoir tous les √©l√®ves evaluated par le contr√¥le
    selected_childs_uuid = list(map(lambda x:x["uuid"], selected_childs))
        # RQ : il y a d√©bat entre la selection de "accessible_childs" et "selected_childs"

    _ = st_create_evaluation(etablissement_connaissances_connues, selected_childs_uuid)


    evaluation_select = st_correction_evaluation_description(user_uuid)

    evaluation_uuid                     = evaluation_select["uuid"]
    childs_evaluated_uuid               = evaluation_select["childs_evaluated"]
    evaluation_connaissances_attendues  = evaluation_select["knowledge_model"] # ex : = ["Priorit√©s op√©ratoires","Expressions litt√©rales"]
    evaluation_connaissances_attendues_index_from_etablissement = list(map(lambda x : etablissement_connaissances_connues.index(x), evaluation_connaissances_attendues))


    childs_evaluated_and_selected           = list(filter(lambda x: x["uuid"] in childs_evaluated_uuid, selected_childs))
    childs_evaluated_and_selected_uuid      = list(map   (lambda x: x["uuid"], childs_evaluated_and_selected))
    childs_evaluated_and_selected_firstName = list(map   (lambda x: x["firstName"][0], childs_evaluated_and_selected))

    with st.expander("Mise √† jour de l'√©valuation :"):
        with st.form(key="√©valuation_modifications"):
            titre     = st.text_area ("Titre de l'√©valuation :"                    , evaluation_select["titre"])
            categorie = st.radio     ("S√©lectionner la cat√©gorie de l'√©valuation :", ["CS", "DM", "CR"],
                                      index = ["CS", "DM", "CR"].index(evaluation_select["category"]))
            beginning     = st.date_input("Date de distribution de l'√©valuation aux √©l√®ves :",
                                        datetime.datetime.strptime(evaluation_select["beginning"], '%Y-%m-%d'))
            collecte  = st.date_input("Date de rendu des √©l√®ves :",
                                        datetime.datetime.strptime(evaluation_select["collecte"], '%Y-%m-%d'))
            rendu     = st.date_input("Date de rendu de l'enseignant :",
                                        datetime.datetime.strptime(evaluation_select["rendu"], '%Y-%m-%d'))
            knowledges = st.multiselect("Quels sont les connaissances utilis√©es ?", st.session_state["etablissement_connaissances_connues"], evaluation_select["knowledge_model"])
            knowledge_NotModel = evaluation_select["knowledge_NotModel"] # RQ : √† adapter suivant la m√™me configuration que la ligne du dessus plus tard

            childs_evaluated = st.multiselect(
                            "Tu d√©sires te renseigner sur quel(s) enfants(s) ?",
                            options = evaluation_select["childs_evaluated"], # selected_childs_uuid,
                            default = childs_evaluated_and_selected_uuid) # evaluation_select["childs_evaluated"]
                # NB : default = evaluation_select["childs_evaluated"]
                #      est actuellement refus√© car les √©l√®ves de l'√©valuation ne sont pas n√©cessairement
                #      dans l'√©valuation => ERROR
            if st.form_submit_button (label="Modification test", help="Click to save") :
                new_evaluation = {
                    "titre"     : titre,
                    "uuid"      : evaluation_select["uuid"],
                    "category"  : categorie, # √©valuation surveill√©, evaluation √† la maison, √©valuation rapide
                    "beginning" : beginning.__str__(),
                    "collecte"  : collecte .__str__(),
                    "rendu"     : rendu    .__str__(),
                    "knowledge_model"   : knowledges,
                        # RQ : Ceci devrait √™tre une liste de int pour structurer au format
                        # De premiers test avec List[comp√©tences] sotn faits, puis cela sera √† num√©riser
                        # avant l'envoi √† l'api
                    "knowledge_NotModel": knowledge_NotModel,
                    "childs_evaluated"  : childs_evaluated
                        # NB : n'est-ce pas aux √©l√®ves que l'on doit assigner k'uuid du test ?
                    #"childs_non_evaluated" : ["uuid5"],
                    #"classe_evaluatede"  : ["class_uuid"]
                    }

                url = API_URL+f'/delete_evaluation/'
                response = requests.post(url, json=evaluation_select, headers=headers)

                url = API_URL+f'/add_evaluation/'
                response = requests.post(url, json=new_evaluation, headers=headers)


                # V√©rifier la r√©ponse
                if response.status_code == 200:
                    st.write("Requ√™te de mise √† jour r√©ussie !")
                    st.experimental_rerun()
                else:
                    st.write("√âchec de la requ√™te :", response.status_code)


    if st.button('Suppression', key=f"suppression_√©valuation"):
        url = API_URL+f'/delete_evaluation/'
        response = requests.post(url, json=evaluation_select, headers=headers)

        # V√©rifier la r√©ponse
        if response.status_code == 200:
            #st.session_state['evaluation_select_id'] = None
            st.experimental_rerun()
            st.write("Requ√™te r√©ussie !")
        else:
            st.write("√âchec de la requ√™te :", response.status_code)
            st.write(response.text)  # Afficher le contenu de la r√©ponse en texte brut


    if not childs_evaluated_and_selected :
        st.info("üòï Aucun des √©l√®ves s√©lection√©s ne sont pr√©sents sur ce test !", icon="üö®")
    else :
        childs_evaluated_and_selected_knowledge = np.concatenate([child["knowledge_Model"] for child in childs_evaluated_and_selected], axis=0).astype(int)
        childs_evaluated_and_selected_knowledge = childs_evaluated_and_selected_knowledge[:,evaluation_connaissances_attendues_index_from_etablissement]

        n_lines = len(evaluation_connaissances_attendues)
        n_cols  = len(childs_evaluated_and_selected)

        with st.expander("Mise √† jour des comp√©tences d'√©l√®ves :"):
            if not evaluation_connaissances_attendues :
                st.write("Aucunes comp√©tences n'a √©t√© associ√©e √† l'√©valuation !")
            else :
                with st.form(key="comp√©tences_modifications"):
                    # Num√©risation des connaissances attendues dans l'√©valuation suivant etablissement_connaissances_connues
                    #connaissances_attendues_numerise, _ = numerizer(evaluation_connaissances_attendues, etablissement_connaissances_connues)
                    #st.write( connaissances_attendues_numerise)
                        # RQ : on admet que les connaissances attendues sont connues par le mod√®le
                        # Sinon, faire un espace de s√©lection d'une notion suivant de teste donn√© (env<=> similarity)
                    #connaissances_attendues_numerise_binar = np.max(connaissances_attendues_numerise, axis= 0)
                    #st.write(connaissances_attendues_numerise_binar)
                    #evaluation_connaissances_attendues_index_from_etablissement = [ind for ind, val in enumerate(etablissement_connaissances_connues) if val in evaluation_connaissances_attendues]


                    X = np.zeros((n_lines, n_cols))
                    table_cols_name = [st.columns([1]*(n_cols+1)) for i in range(n_lines+1)]
                    for n_row, table_row in enumerate(table_cols_name):
                        for n_col, table_col in enumerate(table_row):
                            if n_row == 0 and n_col > 0:
                                word = childs_evaluated_and_selected_firstName[n_col-1]
                                table_cols_name[n_row][n_col].write(word)
                            elif n_row > 0 and n_col == 0 :
                                word = evaluation_connaissances_attendues[n_row-1]
                                table_cols_name[n_row][n_col].write(word)
                            elif n_row != 0 and n_col != 0 :
                                value = childs_evaluated_and_selected_knowledge[n_col-1, n_row-1]
                                key = f"selectcompetences_{n_row}_{n_col}"
                                #X[n_row-1][n_col-1] = table_cols_name[n_row][n_col].checkbox("", value = value, key = key)
                                _ = table_cols_name[n_row][n_col].select_slider(
                                                                "hidden",
                                                                label_visibility="hidden",
                                                                options=["NA", "ECA", "A", "T"],
                                                                value=["NA", "ECA", "A", "T"][value],
                                                                key=key)
                                X[n_row-1][n_col-1] = ["NA", "ECA", "A", "T"].index(_)


                    transmission = st.form_submit_button (label="Modification test", help="Click to save")
                    if transmission:
                        # RQ : Cela demande au pr√©alable que les r√©sultats de chaque √©valuations
                        # auxquelles l'√©l√®ve a particip√© soient r√©pertori√©es sur ses donn√©es
                        # child_evaluations = [evaluations]
                        # evaluation = {"evaluation_id":
                        #               "results_model": ...
                        #               "results_notModel": ... }
                        childs_results = np.transpose(X, (1,0))
                        for child, child_results in zip(childs_evaluated_and_selected, childs_results) :
                            evaluation = {"uuid": evaluation_uuid,
                                       "results_model": child_results,
                                       "results_notModel": [] } # RQ : non pris en compte

                            # i
                            child_index = None
                            for i_child, selected_child in enumerate(selected_childs):
                                if selected_child["uuid"]==child["uuid"] :
                                    child_index=i_child
                                    break

                            child_evaluations = st.session_state["selected_childs"][i_child]["results"]
                            in_child_evaluations = False
                            for i_eval, child_evaluation in enumerate(child_evaluations):
                                if child_evaluation["uuid"]==evaluation["uuid"] :
                                    in_child_evaluations = i_eval
                                    break

                            if in_child_evaluations == False :
                                st.session_state["selected_childs"][i_child]["results"] += [evaluation]
                            else : # in_evaluation in |[0, 1, ...]|
                                st.session_state["selected_childs"][i_child]["results"][i_eval] = evaluation

                            # maj de "knowledge_Model" suivant evaluation["results_model"]
                            for i_evaluation_competence, indice_evaluation_connaissance_attendue in enumerate(evaluation_connaissances_attendues_index_from_etablissement) :
                                i_competence = indice_evaluation_connaissance_attendue
                                st.session_state["selected_childs"][i_child]["knowledge_Model"][0][i_competence] = \
                                    evaluation["results_model"][i_evaluation_competence]
                                    #<=>st.session_state["selected_childs"][i_child]["evaluations"][i_eval][i_evaluation_competence]

                        # SAUVEGARDE DES DONNEES DANS LA BDD ETABLISSEMENT
                        evaluation = {
                            "uuid" : evaluation_uuid,
                            "childs_uuid" : childs_evaluated_and_selected_uuid,
                            "childs_competences" : X.tolist(),
                            "etablissement_connaissances_connues" : etablissement_connaissances_connues}

                        url = API_URL+f'/habilities_evaluation/'
                        response = requests.post(url, json=evaluation, headers=headers)
                        if response.status_code == 200:
                            st.success('Skills are saves !', icon="‚úÖ")
                            #st.experimental_rerun()
                        else:
                            st.error("√âchec de sauvegarde des comp√©tences √©l√®ves sur l'√©valuation s√©lectionn√© dans la DB")





        st.write("<h2>Communication des nouvelles comp√©tences.</h2>", unsafe_allow_html=True)
        cols = st.tabs(childs_evaluated_and_selected_firstName)
        for i_child_evaluated_and_selected, child_evaluated_and_selected, col in zip(range(len(childs_evaluated_and_selected)), childs_evaluated_and_selected, cols):
            # OK knowledge_model
            habilities = {}
            for evaluation_connaissance_attendue in evaluation_connaissances_attendues :
                index_evaluation_connaissance_attendue = etablissement_connaissances_connues.index(evaluation_connaissance_attendue)
                index_hability = child_evaluated_and_selected["knowledge_Model"][0][index_evaluation_connaissance_attendue]
                hability = ["NA", "ECA", "A", "T"][int(index_hability)]
                habilities[evaluation_connaissance_attendue] = hability
                    # RQ : la liste ["NA", "ECA", "A", "T"] est utilis√©e sur de multiples pages
                    #   ->? Mise en place d'une variable g√©n√©rale ?
                    # RQ : Dans le cadre o√π hability in ["NA", "ECA"], une pr√©cision plus pr√©cise des
                    #      comp√©tences peut √™tre mise en place via :
                    #         -> celles demand√©es pour l'acqu√©rir (notions pr√©c√©dentes)
                    #         -> les actions d'entra√Ænnement possibles pour l'acqu√©rir (exercices sur la notion)
            # RQ : ajouter un deuxi√®me for sur evaluation_select["knowledge_NotModel"]

            text_actual_eval = "\n\t\t\t\t".join([""] + [f"- {k} : {v}" for k, v in habilities.items()])

            with col:
                text = f"""Chers parents de {child_evaluated_and_selected["firstName"][0]} :

                Sur l'√©valuation effectu√©e le {evaluation_select["collecte"]} en math√©matiques, voici le bilan associ√© √† ses comp√©tences :{text_actual_eval}"""
                # RQ : les sous-cat√©gories peuvent se formuler ainsi :
                # - Th√©or√®me de Pythagore : Non acquis
                #      - Racine carr√©e : Non acquis
                #      - Equations du premier degr√© : Acquis
                #      - Cat√©gories de triangles : Acquis
                courriel_content = st.text_area("hidden", label_visibility="hidden", value=text, height=20+35*text.count("\n")+100)
                    # NB : height = ax+b o√π a et b sont √† d√©finir

                if st.button('Envoi', key=f"envoi_{i_child_evaluated_and_selected}"):
                    st.write(f'Message envoy√© aux parents de {child_evaluated_and_selected["firstName"][0]} :')

